{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07-5. Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 974,
     "status": "ok",
     "timestamp": 1731458143901,
     "user": {
      "displayName": "천국",
      "userId": "14827418028065544275"
     },
     "user_tz": -540
    },
    "id": "G4--53mR94eH",
    "outputId": "a922d0e9-f3a2-4769-edb4-0d9d95d2e6b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29, 9, 1, 29, 33, 1, 27, 10, 1, 8, 28, 2, 0, 37, 25, 19, 34, 30, 1, 37, 18, 12, 4, 1, 23, 26, 24, 12, 13, 3, 0, 37, 25, 19, 34, 11, 1, 22, 31, 16, 1, 35, 32, 1, 20, 15, 1, 5, 7, 2, 0, 37, 18, 12, 11, 1, 6, 31, 16, 1, 21, 14, 17, 1, 36, 15, 1, 5, 24, 12, 13, 3, 0]\n",
      "['옛', '날', ' ', '옛', '적', ' ', '어', '느', ' ', '곳', '에', ',', '\\n', '할', '아', '버', '지', '와', ' ', '할', '머', '니', '가', ' ', '살', '았', '습', '니', '다', '.', '\\n', '할', '아', '버', '지', '는', ' ', '산', '으', '로', ' ', '풀', '을', ' ', '베', '러', ' ', '갔', '고', ',', '\\n', '할', '머', '니', '는', ' ', '강', '으', '로', ' ', '빨', '래', '를', ' ', '하', '러', ' ', '갔', '습', '니', '다', '.', '\\n']\n",
      "옛날 옛적 어느 곳에,\n",
      "할아버지와 할머니가 살았습니다.\n",
      "할아버지는 산으로 풀을 베러 갔고,\n",
      "할머니는 강으로 빨래를 하러 갔습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RNN 언어 모델\n",
    "\n",
    "text_data = \"\"\"옛날 옛적 어느 곳에,\n",
    "할아버지와 할머니가 살았습니다.\n",
    "할아버지는 산으로 풀을 베러 갔고,\n",
    "할머니는 강으로 빨래를 하러 갔습니다.\n",
    "\"\"\"\n",
    "\n",
    "# text_data 문자열을 set(집합)을 사용하여 중복 제거 & sorted로 정렬\n",
    "char_to_int = {char : i for i, char in enumerate(sorted(set(text_data)))}\n",
    "int_to_char = {i:char for char, i in char_to_int.items()}\n",
    "\n",
    "encoded = [char_to_int[c] for c in text_data]\n",
    "decoded = [int_to_char[c] for c in encoded]\n",
    "\n",
    "print(encoded)\n",
    "print(decoded)\n",
    "\n",
    "print(''.join(decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1731458654669,
     "user": {
      "displayName": "천국",
      "userId": "14827418028065544275"
     },
     "user_tz": -540
    },
    "id": "bGtOx5I2EwFn",
    "outputId": "ef1c4644-fbdb-421e-de4e-42186c9392cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "print(len(encoded))\n",
    "print(len(decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1731458695101,
     "user": {
      "displayName": "천국",
      "userId": "14827418028065544275"
     },
     "user_tz": -540
    },
    "id": "QHvGaRKxFCaQ",
    "outputId": "ed8e2aeb-69f8-4d40-b7d1-330d373dd6be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제일 짧은 문장(첫 번째 문장)을 기준으로 한 글자 수 (공백 포함)\n",
    "seq_length = len(text_data.split(\"\\n\")[0])\n",
    "seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1731458971540,
     "user": {
      "displayName": "천국",
      "userId": "14827418028065544275"
     },
     "user_tz": -540
    },
    "id": "q_ogvWSBFmjB",
    "outputId": "225ae80b-8fab-4198-9efc-2f2ea0ba843e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시퀀스 길이:12\n",
      "레코드 수:61\n",
      "샘플(처음 3건):\n",
      "[[29, 9, 1, 29, 33, 1, 27, 10, 1, 8, 28, 2, 0], [9, 1, 29, 33, 1, 27, 10, 1, 8, 28, 2, 0, 37], [1, 29, 33, 1, 27, 10, 1, 8, 28, 2, 0, 37, 25]]\n"
     ]
    }
   ],
   "source": [
    "encoded_text = encoded\n",
    "\n",
    "sequences = []\n",
    "# 첫 문장의 글자 수를 빼고 나머지 글자 수만큼 반복\n",
    "for i in range(len(encoded_text) - seq_length):\n",
    "    # 인덱스의 끝에 +1을 하여 마지막 글자까지 읽어오게 함\n",
    "    sequences.append(encoded_text[i:i+seq_length+1])\n",
    "\n",
    "print(f\"시퀀스 길이:{seq_length}\")\n",
    "print(f\"레코드 수:{len(sequences)}\")\n",
    "print(f\"샘플(처음 3건):\\n{sequences[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1731459135094,
     "user": {
      "displayName": "천국",
      "userId": "14827418028065544275"
     },
     "user_tz": -540
    },
    "id": "6veJie1TKWgw",
    "outputId": "1b451e6c-7010-4946-b7bb-ee19c5e92fc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 12)\n",
      "(61, 12)\n",
      "[[29  9  1 29 33  1 27 10  1  8 28  2]\n",
      " [ 9  1 29 33  1 27 10  1  8 28  2  0]\n",
      " [ 1 29 33  1 27 10  1  8 28  2  0 37]\n",
      " [29 33  1 27 10  1  8 28  2  0 37 25]\n",
      " [33  1 27 10  1  8 28  2  0 37 25 19]]\n",
      "[[ 9  1 29 33  1 27 10  1  8 28  2  0]\n",
      " [ 1 29 33  1 27 10  1  8 28  2  0 37]\n",
      " [29 33  1 27 10  1  8 28  2  0 37 25]\n",
      " [33  1 27 10  1  8 28  2  0 37 25 19]\n",
      " [ 1 27 10  1  8 28  2  0 37 25 19 34]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 입력 데이터와 타깃 데이터 생성\n",
    "X = np.array([seq[:-1] for seq in sequences]) # 신경망 모델에서 입력 데이터의 길이는 항상 고정 >> sequence 길이 >> 12개\n",
    "y = np.array([seq[1:] for seq in sequences])  # 문장들이 모두 같은 길이라고 할 때, 다음 글자 예측\n",
    "\n",
    "# e.g. '옛날 옛적 어느 곳에,' 문장\n",
    "# X: '옛날 옛적 어느 곳에'\n",
    "# y: '날 옛적 어느 곳에,'\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 4031,
     "status": "ok",
     "timestamp": 1731459218498,
     "user": {
      "displayName": "천국",
      "userId": "14827418028065544275"
     },
     "user_tz": -540
    },
    "id": "H_m07bxiRWAQ",
    "outputId": "a9304000-7fc3-4156-b117-45afc5340af1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 모델 정의\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(len(char_to_int), 64, input_length=seq_length),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(len(char_to_int), activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9202,
     "status": "ok",
     "timestamp": 1731459233618,
     "user": {
      "displayName": "천국",
      "userId": "14827418028065544275"
     },
     "user_tz": -540
    },
    "id": "fVnLoaeKUR42",
    "outputId": "5c117f49-8212-4eb6-eb78-0ff501c9b0d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 3s - 3s/step - accuracy: 0.0301 - loss: 3.6368\n",
      "Epoch 2/100\n",
      "1/1 - 0s - 75ms/step - accuracy: 0.1639 - loss: 3.6289\n",
      "Epoch 3/100\n",
      "1/1 - 0s - 117ms/step - accuracy: 0.2295 - loss: 3.6207\n",
      "Epoch 4/100\n",
      "1/1 - 0s - 56ms/step - accuracy: 0.2350 - loss: 3.6120\n",
      "Epoch 5/100\n",
      "1/1 - 0s - 75ms/step - accuracy: 0.2363 - loss: 3.6024\n",
      "Epoch 6/100\n",
      "1/1 - 0s - 50ms/step - accuracy: 0.2377 - loss: 3.5916\n",
      "Epoch 7/100\n",
      "1/1 - 0s - 51ms/step - accuracy: 0.2363 - loss: 3.5795\n",
      "Epoch 8/100\n",
      "1/1 - 0s - 47ms/step - accuracy: 0.2336 - loss: 3.5654\n",
      "Epoch 9/100\n",
      "1/1 - 0s - 56ms/step - accuracy: 0.2281 - loss: 3.5492\n",
      "Epoch 10/100\n",
      "1/1 - 0s - 42ms/step - accuracy: 0.2254 - loss: 3.5302\n",
      "Epoch 11/100\n",
      "1/1 - 0s - 59ms/step - accuracy: 0.2186 - loss: 3.5077\n",
      "Epoch 12/100\n",
      "1/1 - 0s - 56ms/step - accuracy: 0.2104 - loss: 3.4812\n",
      "Epoch 13/100\n",
      "1/1 - 0s - 46ms/step - accuracy: 0.2090 - loss: 3.4498\n",
      "Epoch 14/100\n",
      "1/1 - 0s - 52ms/step - accuracy: 0.2049 - loss: 3.4135\n",
      "Epoch 15/100\n",
      "1/1 - 0s - 42ms/step - accuracy: 0.2022 - loss: 3.3737\n",
      "Epoch 16/100\n",
      "1/1 - 0s - 57ms/step - accuracy: 0.1995 - loss: 3.3381\n",
      "Epoch 17/100\n",
      "1/1 - 0s - 59ms/step - accuracy: 0.1995 - loss: 3.3245\n",
      "Epoch 18/100\n",
      "1/1 - 0s - 58ms/step - accuracy: 0.1995 - loss: 3.3213\n",
      "Epoch 19/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.2036 - loss: 3.2991\n",
      "Epoch 20/100\n",
      "1/1 - 0s - 42ms/step - accuracy: 0.2090 - loss: 3.2643\n",
      "Epoch 21/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 0.2172 - loss: 3.2290\n",
      "Epoch 22/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.2240 - loss: 3.1985\n",
      "Epoch 23/100\n",
      "1/1 - 0s - 58ms/step - accuracy: 0.2309 - loss: 3.1715\n",
      "Epoch 24/100\n",
      "1/1 - 0s - 68ms/step - accuracy: 0.2418 - loss: 3.1446\n",
      "Epoch 25/100\n",
      "1/1 - 0s - 57ms/step - accuracy: 0.2486 - loss: 3.1157\n",
      "Epoch 26/100\n",
      "1/1 - 0s - 51ms/step - accuracy: 0.2555 - loss: 3.0835\n",
      "Epoch 27/100\n",
      "1/1 - 0s - 43ms/step - accuracy: 0.2568 - loss: 3.0477\n",
      "Epoch 28/100\n",
      "1/1 - 0s - 59ms/step - accuracy: 0.2609 - loss: 3.0086\n",
      "Epoch 29/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 0.2555 - loss: 2.9670\n",
      "Epoch 30/100\n",
      "1/1 - 0s - 43ms/step - accuracy: 0.2555 - loss: 2.9239\n",
      "Epoch 31/100\n",
      "1/1 - 0s - 58ms/step - accuracy: 0.2609 - loss: 2.8803\n",
      "Epoch 32/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.2773 - loss: 2.8374\n",
      "Epoch 33/100\n",
      "1/1 - 0s - 59ms/step - accuracy: 0.2883 - loss: 2.7956\n",
      "Epoch 34/100\n",
      "1/1 - 0s - 44ms/step - accuracy: 0.3046 - loss: 2.7548\n",
      "Epoch 35/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 0.3142 - loss: 2.7145\n",
      "Epoch 36/100\n",
      "1/1 - 0s - 58ms/step - accuracy: 0.3251 - loss: 2.6741\n",
      "Epoch 37/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 0.3292 - loss: 2.6336\n",
      "Epoch 38/100\n",
      "1/1 - 0s - 59ms/step - accuracy: 0.3361 - loss: 2.5929\n",
      "Epoch 39/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.3320 - loss: 2.5521\n",
      "Epoch 40/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 0.3320 - loss: 2.5110\n",
      "Epoch 41/100\n",
      "1/1 - 0s - 58ms/step - accuracy: 0.3320 - loss: 2.4696\n",
      "Epoch 42/100\n",
      "1/1 - 0s - 61ms/step - accuracy: 0.3333 - loss: 2.4281\n",
      "Epoch 43/100\n",
      "1/1 - 0s - 126ms/step - accuracy: 0.3374 - loss: 2.3868\n",
      "Epoch 44/100\n",
      "1/1 - 0s - 59ms/step - accuracy: 0.3429 - loss: 2.3458\n",
      "Epoch 45/100\n",
      "1/1 - 0s - 58ms/step - accuracy: 0.3511 - loss: 2.3053\n",
      "Epoch 46/100\n",
      "1/1 - 0s - 43ms/step - accuracy: 0.3620 - loss: 2.2652\n",
      "Epoch 47/100\n",
      "1/1 - 0s - 44ms/step - accuracy: 0.3702 - loss: 2.2254\n",
      "Epoch 48/100\n",
      "1/1 - 0s - 59ms/step - accuracy: 0.3798 - loss: 2.1859\n",
      "Epoch 49/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 0.3921 - loss: 2.1466\n",
      "Epoch 50/100\n",
      "1/1 - 0s - 58ms/step - accuracy: 0.4016 - loss: 2.1074\n",
      "Epoch 51/100\n",
      "1/1 - 0s - 56ms/step - accuracy: 0.4044 - loss: 2.0681\n",
      "Epoch 52/100\n",
      "1/1 - 0s - 55ms/step - accuracy: 0.4126 - loss: 2.0285\n",
      "Epoch 53/100\n",
      "1/1 - 0s - 64ms/step - accuracy: 0.4385 - loss: 1.9890\n",
      "Epoch 54/100\n",
      "1/1 - 0s - 50ms/step - accuracy: 0.4508 - loss: 1.9496\n",
      "Epoch 55/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 0.4740 - loss: 1.9100\n",
      "Epoch 56/100\n",
      "1/1 - 0s - 60ms/step - accuracy: 0.4904 - loss: 1.8702\n",
      "Epoch 57/100\n",
      "1/1 - 0s - 42ms/step - accuracy: 0.5137 - loss: 1.8306\n",
      "Epoch 58/100\n",
      "1/1 - 0s - 48ms/step - accuracy: 0.5301 - loss: 1.7917\n",
      "Epoch 59/100\n",
      "1/1 - 0s - 73ms/step - accuracy: 0.5478 - loss: 1.7535\n",
      "Epoch 60/100\n",
      "1/1 - 0s - 64ms/step - accuracy: 0.5533 - loss: 1.7151\n",
      "Epoch 61/100\n",
      "1/1 - 0s - 43ms/step - accuracy: 0.5560 - loss: 1.6767\n",
      "Epoch 62/100\n",
      "1/1 - 0s - 47ms/step - accuracy: 0.5628 - loss: 1.6384\n",
      "Epoch 63/100\n",
      "1/1 - 0s - 55ms/step - accuracy: 0.5710 - loss: 1.6002\n",
      "Epoch 64/100\n",
      "1/1 - 0s - 45ms/step - accuracy: 0.5847 - loss: 1.5620\n",
      "Epoch 65/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.5984 - loss: 1.5241\n",
      "Epoch 66/100\n",
      "1/1 - 0s - 59ms/step - accuracy: 0.6093 - loss: 1.4867\n",
      "Epoch 67/100\n",
      "1/1 - 0s - 63ms/step - accuracy: 0.6284 - loss: 1.4497\n",
      "Epoch 68/100\n",
      "1/1 - 0s - 46ms/step - accuracy: 0.6462 - loss: 1.4132\n",
      "Epoch 69/100\n",
      "1/1 - 0s - 58ms/step - accuracy: 0.6667 - loss: 1.3770\n",
      "Epoch 70/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.6858 - loss: 1.3415\n",
      "Epoch 71/100\n",
      "1/1 - 0s - 59ms/step - accuracy: 0.7022 - loss: 1.3066\n",
      "Epoch 72/100\n",
      "1/1 - 0s - 57ms/step - accuracy: 0.7172 - loss: 1.2721\n",
      "Epoch 73/100\n",
      "1/1 - 0s - 58ms/step - accuracy: 0.7268 - loss: 1.2381\n",
      "Epoch 74/100\n",
      "1/1 - 0s - 59ms/step - accuracy: 0.7432 - loss: 1.2046\n",
      "Epoch 75/100\n",
      "1/1 - 0s - 50ms/step - accuracy: 0.7582 - loss: 1.1715\n",
      "Epoch 76/100\n",
      "1/1 - 0s - 56ms/step - accuracy: 0.7691 - loss: 1.1389\n",
      "Epoch 77/100\n",
      "1/1 - 0s - 64ms/step - accuracy: 0.7773 - loss: 1.1070\n",
      "Epoch 78/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 0.7814 - loss: 1.0758\n",
      "Epoch 79/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.7923 - loss: 1.0452\n",
      "Epoch 80/100\n",
      "1/1 - 0s - 57ms/step - accuracy: 0.7978 - loss: 1.0152\n",
      "Epoch 81/100\n",
      "1/1 - 0s - 42ms/step - accuracy: 0.8033 - loss: 0.9861\n",
      "Epoch 82/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 0.8115 - loss: 0.9577\n",
      "Epoch 83/100\n",
      "1/1 - 0s - 59ms/step - accuracy: 0.8169 - loss: 0.9302\n",
      "Epoch 84/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.8238 - loss: 0.9035\n",
      "Epoch 85/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 0.8306 - loss: 0.8776\n",
      "Epoch 86/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 0.8333 - loss: 0.8525\n",
      "Epoch 87/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.8361 - loss: 0.8282\n",
      "Epoch 88/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 0.8415 - loss: 0.8048\n",
      "Epoch 89/100\n",
      "1/1 - 0s - 57ms/step - accuracy: 0.8470 - loss: 0.7823\n",
      "Epoch 90/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.8552 - loss: 0.7605\n",
      "Epoch 91/100\n",
      "1/1 - 0s - 57ms/step - accuracy: 0.8579 - loss: 0.7394\n",
      "Epoch 92/100\n",
      "1/1 - 0s - 57ms/step - accuracy: 0.8620 - loss: 0.7191\n",
      "Epoch 93/100\n",
      "1/1 - 0s - 57ms/step - accuracy: 0.8689 - loss: 0.6995\n",
      "Epoch 94/100\n",
      "1/1 - 0s - 52ms/step - accuracy: 0.8702 - loss: 0.6805\n",
      "Epoch 95/100\n",
      "1/1 - 0s - 62ms/step - accuracy: 0.8716 - loss: 0.6622\n",
      "Epoch 96/100\n",
      "1/1 - 0s - 60ms/step - accuracy: 0.8743 - loss: 0.6446\n",
      "Epoch 97/100\n",
      "1/1 - 0s - 123ms/step - accuracy: 0.8811 - loss: 0.6276\n",
      "Epoch 98/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.8811 - loss: 0.6112\n",
      "Epoch 99/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.8825 - loss: 0.5954\n",
      "Epoch 100/100\n",
      "1/1 - 0s - 67ms/step - accuracy: 0.8852 - loss: 0.5802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f2001d8c760>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X, y, epochs=100, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1910,
     "status": "ok",
     "timestamp": 1731459284318,
     "user": {
      "displayName": "천국",
      "userId": "14827418028065544275"
     },
     "user_tz": -540
    },
    "id": "UUNEWQqKYBO5",
    "outputId": "23bfcbcc-1411-4608-dedf-f93350c2940c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "옛날 옛적 어느 곳에,\n",
      "할아버지와 할머니가 살았습니\n"
     ]
    }
   ],
   "source": [
    "# 생성하고자 하는 텍스트의 초기 시퀀스 지정\n",
    "initial_text = \"옛날 옛적 어느 곳에,\"  # 첫 번째 레코드를 첫 문장으로 넣음\n",
    "\n",
    "# 텍스트 생성\n",
    "max_output_tokens = 16\n",
    "\n",
    "for _ in range(max_output_tokens):\n",
    "  encoded_initial_text = [char_to_int[char] for char in initial_text]\n",
    "  predicted_char = model.predict(np.array([encoded_initial_text]))[:, -1]\n",
    "  next_char = int_to_char[np.argmax(predicted_char)]\n",
    "  initial_text += next_char\n",
    "\n",
    "print(initial_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16964,
     "status": "ok",
     "timestamp": 1731463122847,
     "user": {
      "displayName": "천국",
      "userId": "14827418028065544275"
     },
     "user_tz": -540
    },
    "id": "PoxnmMpUA_Or",
    "outputId": "823eb3b2-efc6-4644-b45b-5ecd5ff05306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 2s - 497ms/step - accuracy: 0.1202 - loss: 3.7768\n",
      "Epoch 2/100\n",
      "4/4 - 0s - 33ms/step - accuracy: 0.3339 - loss: 3.7465\n",
      "Epoch 3/100\n",
      "4/4 - 0s - 34ms/step - accuracy: 0.3455 - loss: 3.7041\n",
      "Epoch 4/100\n",
      "4/4 - 0s - 35ms/step - accuracy: 0.2979 - loss: 3.6374\n",
      "Epoch 5/100\n",
      "4/4 - 0s - 34ms/step - accuracy: 0.2511 - loss: 3.5225\n",
      "Epoch 6/100\n",
      "4/4 - 0s - 35ms/step - accuracy: 0.1974 - loss: 3.3728\n",
      "Epoch 7/100\n",
      "4/4 - 0s - 36ms/step - accuracy: 0.2266 - loss: 3.2243\n",
      "Epoch 8/100\n",
      "4/4 - 0s - 27ms/step - accuracy: 0.3129 - loss: 3.0236\n",
      "Epoch 9/100\n",
      "4/4 - 0s - 32ms/step - accuracy: 0.4017 - loss: 2.8127\n",
      "Epoch 10/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.4086 - loss: 2.5942\n",
      "Epoch 11/100\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.4322 - loss: 2.3825\n",
      "Epoch 12/100\n",
      "4/4 - 0s - 34ms/step - accuracy: 0.4936 - loss: 2.1987\n",
      "Epoch 13/100\n",
      "4/4 - 0s - 27ms/step - accuracy: 0.5416 - loss: 2.0308\n",
      "Epoch 14/100\n",
      "4/4 - 0s - 32ms/step - accuracy: 0.5734 - loss: 1.8781\n",
      "Epoch 15/100\n",
      "4/4 - 0s - 36ms/step - accuracy: 0.6305 - loss: 1.7335\n",
      "Epoch 16/100\n",
      "4/4 - 0s - 29ms/step - accuracy: 0.6687 - loss: 1.6015\n",
      "Epoch 17/100\n",
      "4/4 - 0s - 27ms/step - accuracy: 0.7197 - loss: 1.4788\n",
      "Epoch 18/100\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.7494 - loss: 1.3644\n",
      "Epoch 19/100\n",
      "4/4 - 0s - 24ms/step - accuracy: 0.7897 - loss: 1.2582\n",
      "Epoch 20/100\n",
      "4/4 - 0s - 33ms/step - accuracy: 0.8279 - loss: 1.1606\n",
      "Epoch 21/100\n",
      "4/4 - 0s - 21ms/step - accuracy: 0.8442 - loss: 1.0681\n",
      "Epoch 22/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.8712 - loss: 0.9845\n",
      "Epoch 23/100\n",
      "4/4 - 0s - 33ms/step - accuracy: 0.8760 - loss: 0.9092\n",
      "Epoch 24/100\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.8807 - loss: 0.8381\n",
      "Epoch 25/100\n",
      "4/4 - 0s - 26ms/step - accuracy: 0.8884 - loss: 0.7753\n",
      "Epoch 26/100\n",
      "4/4 - 0s - 30ms/step - accuracy: 0.8893 - loss: 0.7164\n",
      "Epoch 27/100\n",
      "4/4 - 0s - 24ms/step - accuracy: 0.8936 - loss: 0.6638\n",
      "Epoch 28/100\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.8948 - loss: 0.6166\n",
      "Epoch 29/100\n",
      "4/4 - 0s - 40ms/step - accuracy: 0.9013 - loss: 0.5726\n",
      "Epoch 30/100\n",
      "4/4 - 0s - 24ms/step - accuracy: 0.9034 - loss: 0.5351\n",
      "Epoch 31/100\n",
      "4/4 - 0s - 34ms/step - accuracy: 0.9107 - loss: 0.5000\n",
      "Epoch 32/100\n",
      "4/4 - 0s - 33ms/step - accuracy: 0.9189 - loss: 0.4684\n",
      "Epoch 33/100\n",
      "4/4 - 0s - 40ms/step - accuracy: 0.9245 - loss: 0.4413\n",
      "Epoch 34/100\n",
      "4/4 - 0s - 25ms/step - accuracy: 0.9253 - loss: 0.4159\n",
      "Epoch 35/100\n",
      "4/4 - 0s - 33ms/step - accuracy: 0.9283 - loss: 0.3941\n",
      "Epoch 36/100\n",
      "4/4 - 0s - 35ms/step - accuracy: 0.9292 - loss: 0.3743\n",
      "Epoch 37/100\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.9339 - loss: 0.3565\n",
      "Epoch 38/100\n",
      "4/4 - 0s - 34ms/step - accuracy: 0.9365 - loss: 0.3411\n",
      "Epoch 39/100\n",
      "4/4 - 0s - 35ms/step - accuracy: 0.9369 - loss: 0.3266\n",
      "Epoch 40/100\n",
      "4/4 - 0s - 24ms/step - accuracy: 0.9378 - loss: 0.3137\n",
      "Epoch 41/100\n",
      "4/4 - 0s - 36ms/step - accuracy: 0.9391 - loss: 0.3017\n",
      "Epoch 42/100\n",
      "4/4 - 0s - 28ms/step - accuracy: 0.9395 - loss: 0.2912\n",
      "Epoch 43/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.9421 - loss: 0.2811\n",
      "Epoch 44/100\n",
      "4/4 - 0s - 36ms/step - accuracy: 0.9442 - loss: 0.2718\n",
      "Epoch 45/100\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.9442 - loss: 0.2636\n",
      "Epoch 46/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.9446 - loss: 0.2555\n",
      "Epoch 47/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.9446 - loss: 0.2487\n",
      "Epoch 48/100\n",
      "4/4 - 0s - 25ms/step - accuracy: 0.9446 - loss: 0.2416\n",
      "Epoch 49/100\n",
      "4/4 - 0s - 34ms/step - accuracy: 0.9451 - loss: 0.2349\n",
      "Epoch 50/100\n",
      "4/4 - 0s - 25ms/step - accuracy: 0.9459 - loss: 0.2289\n",
      "Epoch 51/100\n",
      "4/4 - 0s - 28ms/step - accuracy: 0.9459 - loss: 0.2235\n",
      "Epoch 52/100\n",
      "4/4 - 0s - 30ms/step - accuracy: 0.9459 - loss: 0.2182\n",
      "Epoch 53/100\n",
      "4/4 - 0s - 32ms/step - accuracy: 0.9464 - loss: 0.2133\n",
      "Epoch 54/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.9464 - loss: 0.2086\n",
      "Epoch 55/100\n",
      "4/4 - 0s - 35ms/step - accuracy: 0.9468 - loss: 0.2043\n",
      "Epoch 56/100\n",
      "4/4 - 0s - 84ms/step - accuracy: 0.9472 - loss: 0.2001\n",
      "Epoch 57/100\n",
      "4/4 - 0s - 42ms/step - accuracy: 0.9472 - loss: 0.1965\n",
      "Epoch 58/100\n",
      "4/4 - 0s - 74ms/step - accuracy: 0.9472 - loss: 0.1925\n",
      "Epoch 59/100\n",
      "4/4 - 0s - 42ms/step - accuracy: 0.9476 - loss: 0.1892\n",
      "Epoch 60/100\n",
      "4/4 - 0s - 74ms/step - accuracy: 0.9481 - loss: 0.1860\n",
      "Epoch 61/100\n",
      "4/4 - 0s - 41ms/step - accuracy: 0.9481 - loss: 0.1831\n",
      "Epoch 62/100\n",
      "4/4 - 0s - 45ms/step - accuracy: 0.9481 - loss: 0.1806\n",
      "Epoch 63/100\n",
      "4/4 - 0s - 42ms/step - accuracy: 0.9494 - loss: 0.1778\n",
      "Epoch 64/100\n",
      "4/4 - 0s - 76ms/step - accuracy: 0.9498 - loss: 0.1755\n",
      "Epoch 65/100\n",
      "4/4 - 0s - 48ms/step - accuracy: 0.9498 - loss: 0.1730\n",
      "Epoch 66/100\n",
      "4/4 - 0s - 60ms/step - accuracy: 0.9498 - loss: 0.1706\n",
      "Epoch 67/100\n",
      "4/4 - 0s - 26ms/step - accuracy: 0.9498 - loss: 0.1685\n",
      "Epoch 68/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.9498 - loss: 0.1665\n",
      "Epoch 69/100\n",
      "4/4 - 0s - 34ms/step - accuracy: 0.9498 - loss: 0.1648\n",
      "Epoch 70/100\n",
      "4/4 - 0s - 35ms/step - accuracy: 0.9502 - loss: 0.1630\n",
      "Epoch 71/100\n",
      "4/4 - 0s - 33ms/step - accuracy: 0.9502 - loss: 0.1612\n",
      "Epoch 72/100\n",
      "4/4 - 0s - 26ms/step - accuracy: 0.9506 - loss: 0.1599\n",
      "Epoch 73/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.9506 - loss: 0.1583\n",
      "Epoch 74/100\n",
      "4/4 - 0s - 34ms/step - accuracy: 0.9511 - loss: 0.1568\n",
      "Epoch 75/100\n",
      "4/4 - 0s - 36ms/step - accuracy: 0.9511 - loss: 0.1555\n",
      "Epoch 76/100\n",
      "4/4 - 0s - 24ms/step - accuracy: 0.9515 - loss: 0.1543\n",
      "Epoch 77/100\n",
      "4/4 - 0s - 34ms/step - accuracy: 0.9515 - loss: 0.1531\n",
      "Epoch 78/100\n",
      "4/4 - 0s - 21ms/step - accuracy: 0.9511 - loss: 0.1519\n",
      "Epoch 79/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.9515 - loss: 0.1508\n",
      "Epoch 80/100\n",
      "4/4 - 0s - 36ms/step - accuracy: 0.9519 - loss: 0.1495\n",
      "Epoch 81/100\n",
      "4/4 - 0s - 33ms/step - accuracy: 0.9519 - loss: 0.1483\n",
      "Epoch 82/100\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.9524 - loss: 0.1474\n",
      "Epoch 83/100\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.9528 - loss: 0.1464\n",
      "Epoch 84/100\n",
      "4/4 - 0s - 25ms/step - accuracy: 0.9528 - loss: 0.1455\n",
      "Epoch 85/100\n",
      "4/4 - 0s - 34ms/step - accuracy: 0.9528 - loss: 0.1447\n",
      "Epoch 86/100\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.9528 - loss: 0.1436\n",
      "Epoch 87/100\n",
      "4/4 - 0s - 21ms/step - accuracy: 0.9528 - loss: 0.1429\n",
      "Epoch 88/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.9528 - loss: 0.1418\n",
      "Epoch 89/100\n",
      "4/4 - 0s - 37ms/step - accuracy: 0.9528 - loss: 0.1412\n",
      "Epoch 90/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.9519 - loss: 0.1405\n",
      "Epoch 91/100\n",
      "4/4 - 0s - 35ms/step - accuracy: 0.9528 - loss: 0.1395\n",
      "Epoch 92/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.9528 - loss: 0.1390\n",
      "Epoch 93/100\n",
      "4/4 - 0s - 34ms/step - accuracy: 0.9528 - loss: 0.1385\n",
      "Epoch 94/100\n",
      "4/4 - 0s - 24ms/step - accuracy: 0.9528 - loss: 0.1374\n",
      "Epoch 95/100\n",
      "4/4 - 0s - 33ms/step - accuracy: 0.9528 - loss: 0.1368\n",
      "Epoch 96/100\n",
      "4/4 - 0s - 36ms/step - accuracy: 0.9532 - loss: 0.1366\n",
      "Epoch 97/100\n",
      "4/4 - 0s - 37ms/step - accuracy: 0.9541 - loss: 0.1354\n",
      "Epoch 98/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.9545 - loss: 0.1352\n",
      "Epoch 99/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.9532 - loss: 0.1343\n",
      "Epoch 100/100\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.9541 - loss: 0.1338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q.미국의 수도는?\n",
      "A.Washington DC\n"
     ]
    }
   ],
   "source": [
    "# 특정 국가(미국) 입력문을 5회씩 반복해서 입력한 코드\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 텍스트 데이터 불러오기\n",
    "# 참고 각 문자 뒤에 스페이스 들어가면 에러 발생\n",
    "text_data = \"\"\"Q.영국의 수도는?\n",
    "A.런던입니다.\n",
    "Q.미국의 수도는?\n",
    "A.Washington DC입니다.\n",
    "Q.미국의 수도는?\n",
    "A.Washington DC입니다.\n",
    "Q.미국의 수도는?\n",
    "A.Washington DC입니다.\n",
    "Q.미국의 수도는?\n",
    "A.Washington DC입니다.\n",
    "Q.한국의 수도는?\n",
    "A.서울입니다.\n",
    "Q.아메리카의 수도는?\n",
    "A.워싱턴 DC입니다。\n",
    "Q.미국의 수도는?\n",
    "A.Washington DC입니다.\n",
    "Q.잉글랜드의 수도는?\n",
    "A.런던입니다.\n",
    "\"\"\"\n",
    "\n",
    "# text_data 문자열을 set(집합)을 사용하여 중복 제거 & sorted로 정렬\n",
    "char_to_int = {char : i for i, char in enumerate(sorted(set(text_data)))}\n",
    "int_to_char = {i:char for char, i in char_to_int.items()}\n",
    "\n",
    "# 텍스트 데이터를 정수열로 변환\n",
    "encoded = [char_to_int[c] for c in text_data]\n",
    "# 정수열 데이터를 텍스트 데이터로 변환\n",
    "decoded = [int_to_char[c] for c in encoded]\n",
    "\n",
    "# 입력 시퀀스와 타킷 시퀀스 만들기\n",
    "seq_length = len(text_data.split(\"\\n\")[0])\n",
    "\n",
    "encoded_text = encoded\n",
    "\n",
    "sequences = []\n",
    "for i in range(len(encoded_text) - seq_length):\n",
    "    sequences.append(encoded_text[i:i+seq_length+1])\n",
    "\n",
    "# 입력 데이터와 타깃 데이터 생성\n",
    "X = np.array([seq[:-1] for seq in sequences])\n",
    "y = np.array([seq[1:] for seq in sequences])\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(len(char_to_int), 64, input_length=seq_length),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(len(char_to_int), activation='softmax')\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X, y, epochs=100, batch_size=64, verbose=2)\n",
    "\n",
    "# 생성할 텍스트의 초기 시퀀스를 지정\n",
    "initial_text = \"Q.미국의 수도는?\"\n",
    "\n",
    "# 텍스트 생성\n",
    "max_output_tokens = 16\n",
    "\n",
    "for _ in range(max_output_tokens):\n",
    "  encoded_initial_text = [char_to_int[char] for char in initial_text]\n",
    "  predicted_char = model.predict(np.array([encoded_initial_text]))[:, -1]\n",
    "\n",
    "  next_char = int_to_char[np.argmax(predicted_char)]\n",
    "  initial_text += next_char\n",
    "\n",
    "print(initial_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_43GZiq9JaZP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMbXziplWaY1Y7fKh6vmA/l",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
